{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "989c4b10",
   "metadata": {},
   "source": [
    "# LangChain: Agents\n",
    "\n",
    "## Outline:\n",
    "\n",
    "* Using built in LangChain tools: DuckDuckGo search and Wikipedia\n",
    "* Defining your own tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561f7505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be24758",
   "metadata": {},
   "source": [
    "## Built-in LangChain tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cb7ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -U wikipedia\n",
    "#%pip install langchain-core\n",
    "#%pip install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddad01fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "#from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.python import PythonREPL\n",
    "#from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4e69ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a1c631",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"llm-math\",\"wikipedia\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9dedd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_structured_chat_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361311c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Tavily Search tool\n",
    "#tools = [TavilySearchResults(max_results=1)]\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "tools = load_tools([\"llm-math\",\"wikipedia\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981c63b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "# Get the prompt to use (you can modify this!)\n",
    "prompt = hub.pull(\"hwchase17/structured-chat-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3785102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the LLM that will drive the agent\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-1106\")\n",
    "\n",
    "# Construct the JSON agent\n",
    "agent = create_structured_chat_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cb6bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an agent executor\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "# Invoke the agent with an input query\n",
    "response = agent_executor.invoke({\"input\": \"what is LangChain?\"})\n",
    "\n",
    "# Print the output\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b66620",
   "metadata": {},
   "source": [
    "## Define your own tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625a80b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install DateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776bc581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58e5762",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def time(text: str) -> str:\n",
    "    \"\"\"Returns todays date, use this for any \\\n",
    "    questions related to knowing todays date. \\\n",
    "    The input should always be an empty string, \\\n",
    "    and this function will always return todays \\\n",
    "    date - any date mathmatics should occur \\\n",
    "    outside this function.\"\"\"\n",
    "    return str(date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5134b547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCould not parse LLM output: I'll need to use a specific tool to find the latest prediction for March 2024. Let me check.\u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mI'll need to use a specific tool to find the latest prediction for March 2024. Let me check.\n",
      "Action:\n",
      "```{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": {\n",
      "    \"query\": \"March 2024 predictions\"\n",
      "  }\n",
      "}```\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: March 2024 lunar eclipse\n",
      "Summary: A penumbral lunar eclipse will take place on Monday, March 25, 2024. It will be visible to the naked eye as 95.57% of the Moon will be immersed in Earth's penumbral shadow.\n",
      "\n",
      "Page: 2024 Indian general election\n",
      "Summary: General elections are expected to be held in India between April and May 2024 to elect 543 members of the Lok Sabha.\n",
      "\n",
      "Page: Solar eclipse of October 2, 2024\n",
      "Summary: An annular solar eclipse will occur on October 2, 2024. A solar eclipse occurs when the Moon passes between Earth and the Sun, thereby totally or partly obscuring the image of the Sun for a viewer on Earth. An annular solar eclipse occurs when the Moon's apparent diameter is smaller than the Sun's, blocking most of the Sun's light and causing the Sun to look like an annulus (ring). An annular eclipse appears as a partial eclipse over a region of the Earth thousands of kilometres wide.\n",
      "Other than Easter Island and a small portion near the southern tips of Argentina and Chile and the north of the Falkland Islands, the path of the eclipse's antumbra will be entirely over the Pacific Ocean. The penumbra will be visible from southern South America, Hawaii and portions of Antarctica. Eclipse magnitude is 0.93261, occurring only 56 minutes before apogee.\n",
      "The next solar eclipse occurs on March 29, 2025.\u001b[0m\u001b[32;1m\u001b[1;3m```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The latest prediction for March 2024 includes a penumbral lunar eclipse on March 25, 2024, and an annular solar eclipse on October 2, 2024.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'what is latest prediction for March 2024?', 'output': 'The latest prediction for March 2024 includes a penumbral lunar eclipse on March 25, 2024, and an annular solar eclipse on October 2, 2024.'}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_structured_chat_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import load_tools\n",
    "\n",
    "# Choose the LLM that will drive the agent\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-1106\")\n",
    "\n",
    "tools = load_tools([\"llm-math\",\"wikipedia\"], llm=llm)\n",
    "prompt = hub.pull(\"hwchase17/structured-chat-agent\")\n",
    "\n",
    "# Construct the JSON agent\n",
    "agent = create_structured_chat_agent(llm, tools, prompt)\n",
    "\n",
    "# Create an agent executor\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools + [time],\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "# Invoke the agent with an input query\n",
    "response = agent_executor.invoke({\"input\": \"what is latest prediction for March 2024?\"})\n",
    "\n",
    "# Print the output\n",
    "print(response)\n",
    "\n",
    "\n",
    "#agent= initialize_agent(\n",
    "#    tools + [time], \n",
    "#    llm, \n",
    "#    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "#    handle_parsing_errors=True,\n",
    "#    verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47313945",
   "metadata": {},
   "source": [
    "**Note**: \n",
    "\n",
    "The agent will sometimes come to the wrong conclusion (agents are a work in progress!). \n",
    "\n",
    "If it does, please try running it again."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
